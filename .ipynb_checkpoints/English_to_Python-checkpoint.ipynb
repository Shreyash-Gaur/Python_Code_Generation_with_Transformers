{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlv7IfhFQhsv"
   },
   "source": [
    "# Data Perparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-mOljzdcIZL"
   },
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "import torchtext\r\n",
    "from torchtext.legacy.data import Field, BucketIterator, Iterator\r\n",
    "from torchtext.legacy import data\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.ticker as ticker\r\n",
    "\r\n",
    "import spacy\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "import random\r\n",
    "import math\r\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "5WZWgUq7N0Qn",
    "outputId": "73a8933f-1c19-4a99-afc9-030c02235d35"
   },
   "outputs": [],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1UTpnAaSUlp"
   },
   "source": [
    "## Reading the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYRncG2sPvbS"
   },
   "outputs": [],
   "source": [
    "f = open(\"english_python_data.txt\", \"r\")\r\n",
    "file_lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wcPoWVXRYqbT",
    "outputId": "b8cde55f-6337-4c25-f148-1b4ce07b6f68"
   },
   "outputs": [],
   "source": [
    "file_lines[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbhPC2wnSbOA"
   },
   "source": [
    "Our dataset is formulated in a manner where every question starts with '#'. Lines between two consecutive '#' forms the solution to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1HR4YOwXXln"
   },
   "outputs": [],
   "source": [
    "dps = []\r\n",
    "dp = None\r\n",
    "for line in file_lines:\r\n",
    "  if line[0] == \"#\":\r\n",
    "    if dp:\r\n",
    "      dp['solution'] = ''.join(dp['solution'])\r\n",
    "      dps.append(dp)\r\n",
    "    dp = {\"question\": None, \"solution\": []}\r\n",
    "    dp['question'] = line[1:]\r\n",
    "  else:\r\n",
    "    dp[\"solution\"].append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VNitByXS7PF"
   },
   "source": [
    "Lets take a look at the first 50 entries of the data we have parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JOvv0T1FaH-V",
    "outputId": "590b87b5-2a87-4e19-e38e-ca6ae73a023c"
   },
   "outputs": [],
   "source": [
    "i=0\r\n",
    "for dp in dps:\r\n",
    "  print(\"\\n Question no: \", i+1)\r\n",
    "  i+=1\r\n",
    "  print(dp['question'][1:])\r\n",
    "  print(dp['solution'])\r\n",
    " 2f i>49:\r\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qA-1MuOecZRt",
    "outputId": "fcf5ae3e-5417-4b77-917a-f05859a56659"
   },
   "outputs": [],
   "source": [
    "print(\"Dataset size:\", len(dps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swBfwcDaXEh5"
   },
   "source": [
    "## Using a custom tokenizer to tokenize python code\r\n",
    "\r\n",
    "Python is a programming language with its own unique syntax. Regular tokenizers like spacy are meant to tokenize english scentences and are not optimized towards Python's syntax. Here, we write our own custom tokenizer that makes use of Python's default [tokenize](https://docs.python.org/3/library/tokenize.html) library. When we make use of this library we only extract the token type and the token string.  \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_UsevXhPgh1R"
   },
   "outputs": [],
   "source": [
    "from tokenize import tokenize, untokenize\r\n",
    "import io\r\n",
    "\r\n",
    "\r\n",
    "def tokenize_python_code(python_code_str):\r\n",
    "    python_tokens = list(tokenize(io.BytesIO(python_code_str.encode('utf-8')).readline))\r\n",
    "    tokenized_output = []\r\n",
    "    for i in range(0, len(python_tokens)):\r\n",
    "        tokenized_output.append((python_tokens[i].type, python_tokens[i].string))\r\n",
    "    return tokenized_output\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2V-sePckv1-K",
    "outputId": "79ca4b9a-6222-4c0d-94fe-eb3a65b384df"
   },
   "outputs": [],
   "source": [
    "tokenized_sample = tokenize_python_code(dps[1]['solution'])\r\n",
    "print(tokenized_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dQ00a5cwwHtL",
    "outputId": "0f444d4d-ab03-472f-97dd-526e9fb46831"
   },
   "outputs": [],
   "source": [
    "print(untokenize(tokenized_sample).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nsoc0eCpb8e"
   },
   "source": [
    "Since we have mere 5000 data points, we make use of data augmentations to increase the size of our dataset. While tokenizing the python code, we mask the names of certain variables randomly(with 'var_1, 'var_2' etc) to ensure that the model that we train does not merly fixate on the way the variables are named and actually tries to understand the inhrent logic and syntax of the python code.\r\n",
    "\r\n",
    "But, while randomly picking varibles to mask we avoid keyword literals(*keyword.kwlist*), control structures(as can be seen in below *skip_list*) and object properties. We add all such literals that need to be skipped into the *skip_list*\r\n",
    "\r\n",
    "```skip_list = ['range', 'enumerate', 'print', 'ord', 'int', 'float', 'char', 'list', 'dict', 'tuple', 'set', 'len', 'sum', 'min', 'max']```\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lM-tqDwhYoVJ",
    "outputId": "f0bf41e6-0880-4ced-86c8-7eb6eb670792"
   },
   "outputs": [],
   "source": [
    "import keyword\r\n",
    "\r\n",
    "print(keyword.kwlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbIMyrYapfwS"
   },
   "outputs": [],
   "source": [
    "def augment_tokenize_python_code(python_code_str, mask_factor=0.3):\r\n",
    "\r\n",
    "\r\n",
    "    var_dict = {} # Dictionary that stores masked variables\r\n",
    "\r\n",
    "    # certain reserved words that should not be treated as normal variables and\r\n",
    "    # hence need to be skipped from our variable mask augmentations\r\n",
    "    skip_list = ['range', 'enumerate', 'print', 'ord', 'int', 'float', 'zip'\r\n",
    "                 'char', 'list', 'dict', 'tuple', 'set', 'len', 'sum', 'min', 'max']\r\n",
    "    skip_list.extend(keyword.kwlist)\r\n",
    "\r\n",
    "    var_counter = 1\r\n",
    "    python_tokens = list(tokenize(io.BytesIO(python_code_str.encode('utf-8')).readline))\r\n",
    "    tokenized_output = []\r\n",
    "\r\n",
    "    for i in range(0, len(python_tokens)):\r\n",
    "      if python_tokens[i].type == 1 and python_tokens[i].string not in skip_list:\r\n",
    "        \r\n",
    "        if i>0 and python_tokens[i-1].string in ['def', '.', 'import', 'raise', 'except', 'class']: # avoid masking modules, functions and error literals\r\n",
    "          skip_list.append(python_tokens[i].string)\r\n",
    "          tokenized_output.append((python_tokens[i].type, python_tokens[i].string))\r\n",
    "        elif python_tokens[i].string in var_dict:  # if variable is already masked\r\n",
    "          tokenized_output.append((python_tokens[i].type, var_dict[python_tokens[i].string]))\r\n",
    "        elif random.uniform(0, 1) > 1-mask_factor: # randomly mask variables\r\n",
    "          var_dict[python_tokens[i].string] = 'var_' + str(var_counter)\r\n",
    "          var_counter+=1\r\n",
    "          tokenized_output.append((python_tokens[i].type, var_dict[python_tokens[i].string]))\r\n",
    "        else:\r\n",
    "          skip_list.append(python_tokens[i].string)\r\n",
    "          tokenized_output.append((python_tokens[i].type, python_tokens[i].string))\r\n",
    "      \r\n",
    "      else:\r\n",
    "        tokenized_output.append((python_tokens[i].type, python_tokens[i].string))\r\n",
    "    \r\n",
    "    return tokenized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HJwaBJOhdxb",
    "outputId": "3145786e-cf3e-4f6c-a230-6a714cde505f"
   },
   "outputs": [],
   "source": [
    "tokenized_sample = augment_tokenize_python_code(dps[1]['solution'])\r\n",
    "print(tokenized_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciLm6oezs3A2",
    "outputId": "d8b1a093-c181-449f-8fa5-d9c59ae51498"
   },
   "outputs": [],
   "source": [
    "print(untokenize(tokenized_sample).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hYArh3OznQ0"
   },
   "source": [
    "As one can see our augmented tokenizer picked num2 randomly and masked(replaced) it with by var_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shdWBNLu0DkK"
   },
   "source": [
    "## Building Train and Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhBx_KFVaJIK"
   },
   "outputs": [],
   "source": [
    "python_problems_df = pd.DataFrame(dps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "6i3TKNUoaWPC",
    "outputId": "fa0ee8e9-6893-4c67-8b63-456e15bc8fd5"
   },
   "outputs": [],
   "source": [
    "python_problems_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_93zNqfepxY",
    "outputId": "b9dd7668-095a-4a99-a29f-c0c861b302ac"
   },
   "outputs": [],
   "source": [
    "python_problems_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cdHbscZsSJu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "np.random.seed(0)\r\n",
    "msk = np.random.rand(len(python_problems_df)) < 0.85 # Splitting data into 85% train and 15% validation\r\n",
    "\r\n",
    "train_df = python_problems_df[msk]\r\n",
    "val_df = python_problems_df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jDtZSkLUu53D",
    "outputId": "a332b531-f0f2-4da7-b09c-0d09f3fd24cf"
   },
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3SkbK0Qu9TZ",
    "outputId": "e5108fb5-fdb8-489f-ef92-d7f59ee5799c"
   },
   "outputs": [],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6u7EyiRZ6brX"
   },
   "source": [
    "## Creating vocabulary using torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3ZQQWsWi4rn"
   },
   "source": [
    "In this section we will use torchtext Fields to construct the vocabulary for our sequence-to-sequence learning problem.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PlIi4zsLKwLE"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\r\n",
    "\r\n",
    "random.seed(SEED)\r\n",
    "torch.manual_seed(SEED)\r\n",
    "torch.cuda.manual_seed(SEED)\r\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLID_2ZtixKY"
   },
   "outputs": [],
   "source": [
    "Input = data.Field(tokenize = 'spacy',\r\n",
    "            init_token='<sos>', \r\n",
    "            eos_token='<eos>', \r\n",
    "            lower=True)\r\n",
    "\r\n",
    "Output = data.Field(tokenize = augment_tokenize_python_code,\r\n",
    "                    init_token='<sos>', \r\n",
    "                    eos_token='<eos>', \r\n",
    "                    lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttEpbc2rixPx"
   },
   "outputs": [],
   "source": [
    "fields = [('Input', Input),('Output', Output)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxsyNTBtogcD"
   },
   "source": [
    "Since our data augmentations have the potential to increase the vocabulary beyond what it initially is, we must ensure that we capture as many variations as possible in the vocabulary that we develop. In the the below code we apply our data augmentations 100 times to ensure that we can capture a majority of augmentations into our vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uP_yJeqjoLLV"
   },
   "outputs": [],
   "source": [
    "train_example = []\r\n",
    "val_example = []\r\n",
    "\r\n",
    "train_expansion_factor = 100\r\n",
    "for j in range(train_expansion_factor):\r\n",
    "  for i in range(train_df.shape[0]):\r\n",
    "      try:\r\n",
    "          ex = data.Example.fromlist([train_df.question[i], train_df.solution[i]], fields)\r\n",
    "          train_example.append(ex)\r\n",
    "      except:\r\n",
    "          pass\r\n",
    "\r\n",
    "for i in range(val_df.shape[0]):\r\n",
    "    try:\r\n",
    "        ex = data.Example.fromlist([val_df.question[i], val_df.solution[i]], fields)\r\n",
    "        val_example.append(ex)\r\n",
    "    except:\r\n",
    "        pass       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ooT2EqpmtcAW"
   },
   "outputs": [],
   "source": [
    "train_data = data.Dataset(train_example, fields)\r\n",
    "valid_data =  data.Dataset(val_example, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uk4zu6Ntqgfr"
   },
   "outputs": [],
   "source": [
    "Input.build_vocab(train_data, min_freq = 0)\r\n",
    "Output.build_vocab(train_data, min_freq = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oA17CYnDJa4D",
    "outputId": "a6fccc99-87b2-46ee-d83a-c6a7b2e4bfa8"
   },
   "outputs": [],
   "source": [
    "Output.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5f1HbzYuEcD"
   },
   "outputs": [],
   "source": [
    "def save_vocab(vocab, path):\r\n",
    "    import pickle\r\n",
    "    output = open(path, 'wb')\r\n",
    "    pickle.dump(vocab, output)\r\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lN6tUrOxuFac"
   },
   "outputs": [],
   "source": [
    "# save_vocab(Input.vocab, \"/content/drive/MyDrive/TheSchoolOfAI/EndCapstone/src_vocab.pkl\")\r\n",
    "# save_vocab(Output.vocab, \"/content/drive/MyDrive/TheSchoolOfAI/EndCapstone/trg_vocab.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4pv-5RpJuAjb",
    "outputId": "315e1aec-e063-44a2-b91f-9d5437c0b1fd"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgNa1xUluGHc",
    "outputId": "6de98ba1-7a01-4b4c-b071-05aeff2a97cd"
   },
   "outputs": [],
   "source": [
    "train_data[0].Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sZedgyzu7cD",
    "outputId": "9fcc8c0d-1ff6-4867-d5fd-3213f62a5226"
   },
   "outputs": [],
   "source": [
    "print(vars(train_data.examples[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njS_msug6eQ3"
   },
   "source": [
    "# Transformer Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd-C0ntd8x1e"
   },
   "source": [
    "Our transformer can be understood in terms of its three components:\r\n",
    "1. An Encoder that encodes an input sequence into state representation vectors.\r\n",
    "2. An Attention mechanism that enables our Transformer model to focus on the right aspects of the sequential input stream. This is used repeatedly within both the encoder and the decoder to help them contextualize the input data.\r\n",
    "3. A Decoder that decodes the state representation vector to generate the target output sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSjhBKP59ntL"
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgvD_MpkC2OS"
   },
   "source": [
    "![](https://raw.githubusercontent.com/bentrevett/pytorch-seq2seq/9479fcb532214ad26fd4bda9fcf081a05e1aaf4e/assets/transformer-encoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQYN9WDA9Hh_"
   },
   "source": [
    "Our Encoder accepts a batch of source sequences and sequence masks as input. The source mask contains 1 in locations where the input sequence has valid values and 0 where the input sequence has <pad> values. This ensures that the attention mechanism within the encoder does not pay attention to <pad> values.\r\n",
    "\r\n",
    "We convert our source sequence tokens into embeddings(‘tok_embedding’) of ‘hid_dim’ length. Since were are not using any recurrent networks we need to tag each token with its positional indices in order to preserve sequential information. We create an indices tensor(i.e. ‘pos’) and convert this into an embedding(‘pos_embedding’) of length ‘hid_dim’. This is combined with the source sequence embeddings to create our initial Encoder Layer input tensor src. This src tensor is passed through a series of Encoder Layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NE6JimgOCz-w"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\r\n",
    "    def __init__(self, \r\n",
    "                 input_dim, \r\n",
    "                 hid_dim, \r\n",
    "                 n_layers, \r\n",
    "                 n_heads, \r\n",
    "                 pf_dim,\r\n",
    "                 dropout, \r\n",
    "                 device,\r\n",
    "                 max_length = 1000):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        self.device = device\r\n",
    "        \r\n",
    "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\r\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\r\n",
    "        \r\n",
    "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \r\n",
    "                                                  n_heads, \r\n",
    "                                                  pf_dim,\r\n",
    "                                                  dropout, \r\n",
    "                                                  device) \r\n",
    "                                     for _ in range(n_layers)])\r\n",
    "        \r\n",
    "        self.dropout = nn.Dropout(dropout)\r\n",
    "        \r\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\r\n",
    "        \r\n",
    "    def forward(self, src, src_mask):\r\n",
    "        \r\n",
    "        #src = [batch size, src len]\r\n",
    "        #src_mask = [batch size, 1, 1, src len]\r\n",
    "        \r\n",
    "        batch_size = src.shape[0]\r\n",
    "        src_len = src.shape[1]\r\n",
    "\r\n",
    "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\r\n",
    "        \r\n",
    "        #pos = [batch size, src len]\r\n",
    "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\r\n",
    "        \r\n",
    "        #src = [batch size, src len, hid dim]\r\n",
    "        \r\n",
    "        for layer in self.layers:\r\n",
    "            src = layer(src, src_mask)\r\n",
    "            \r\n",
    "        #src = [batch size, src len, hid dim]\r\n",
    "            \r\n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1E12pQr9REU"
   },
   "source": [
    "An EncoderLayer is the basic building block of our Transformer’s Encoder component. Our src tensor along with its ‘src_mask’ are sent into a multi-head self-attention operation to help our model focus on the necessary aspects of the src tensor. The output from the attention operation is combined with the src tensor(via skip connection) and normalized to avoid vanishing/exploding gradients(during training). This combined output is sent into a PositionwiseFeedForwardLayer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LheiXWVFDEg"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\r\n",
    "    def __init__(self, \r\n",
    "                 hid_dim, \r\n",
    "                 n_heads, \r\n",
    "                 pf_dim,  \r\n",
    "                 dropout, \r\n",
    "                 device):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\r\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \r\n",
    "                                                                     pf_dim, \r\n",
    "                                                                     dropout)\r\n",
    "        self.dropout = nn.Dropout(dropout)\r\n",
    "        \r\n",
    "    def forward(self, src, src_mask):\r\n",
    "        \r\n",
    "        #src = [batch size, src len, hid dim]\r\n",
    "        #src_mask = [batch size, 1, 1, src len] \r\n",
    "                \r\n",
    "        #self attention\r\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\r\n",
    "        \r\n",
    "        #dropout, residual connection and layer norm\r\n",
    "        src = self.self_attn_layer_norm(src + self.dropout(_src))\r\n",
    "        \r\n",
    "        #src = [batch size, src len, hid dim]\r\n",
    "        \r\n",
    "        #positionwise feedforward\r\n",
    "        _src = self.positionwise_feedforward(src)\r\n",
    "        \r\n",
    "        #dropout, residual and layer norm\r\n",
    "        src = self.ff_layer_norm(src + self.dropout(_src))\r\n",
    "        \r\n",
    "        #src = [batch size, src len, hid dim]\r\n",
    "        \r\n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6h_Iqnk4Jg5k"
   },
   "source": [
    "![](https://raw.githubusercontent.com/bentrevett/pytorch-seq2seq/9479fcb532214ad26fd4bda9fcf081a05e1aaf4e/assets/transformer-attention.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjEVmTzG9uZ4"
   },
   "source": [
    "A PositionwiseFeedForwardLayer takes the combined input and processes it further using two fully connected layers and a Relu activation function between them. This in combination with the src embedding is the final output of an EncoderLayer. This process repeats for each EncoderLayer block.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9w9xDUKL7LU"
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\r\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\r\n",
    "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\r\n",
    "        \r\n",
    "        self.dropout = nn.Dropout(dropout)\r\n",
    "        \r\n",
    "    def forward(self, x):\r\n",
    "        \r\n",
    "        #x = [batch size, seq len, hid dim]\r\n",
    "        \r\n",
    "        x = self.dropout(torch.relu(self.fc_1(x)))\r\n",
    "        \r\n",
    "        #x = [batch size, seq len, pf dim]\r\n",
    "        \r\n",
    "        x = self.fc_2(x)\r\n",
    "        \r\n",
    "        #x = [batch size, seq len, hid dim]\r\n",
    "        \r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VroGxzNo-GGI"
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3MtR2yd-Iaz"
   },
   "source": [
    "Attention is a mechanism that allows a model to focus on the necessary parts of the input sequence as per the demands of the task at hand.\r\n",
    "\r\n",
    "Researchers at google like to look at everything as an information retrieval problem. Therefore the [“Attention is all you need”](https://arxiv.org/abs/1706.03762) paper tries to look at attention in terms of “Query”, “Keys” and “Values”. A search engine accepts a “Query” and tries to match it up with Indices(i.e. Keys) in order to get appropriate values as results for the query. Similarly one can think of attention as a mechanism in which the query vector and key vector work towards getting the right attention weights(i.e. values).\r\n",
    "\r\n",
    "When multiple channels(or heads) of attention are applied in parallel to a single source, it is known as multi-head attention. This increases the learning capacity of the model and therefore leads to better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZmeHfGhGzkN"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\r\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "        assert hid_dim % n_heads == 0\r\n",
    "        \r\n",
    "        self.hid_dim = hid_dim\r\n",
    "        self.n_heads = n_heads\r\n",
    "        self.head_dim = hid_dim // n_heads\r\n",
    "        \r\n",
    "        self.fc_q = nn.Linear(hid_dim, hid_dim)\r\n",
    "        self.fc_k = nn.Linear(hid_dim, hid_dim)\r\n",
    "        self.fc_v = nn.Linear(hid_dim, hid_dim)\r\n",
    "        \r\n",
    "        self.fc_o = nn.Linear(hid_dim, hid_dim)\r\n",
    "        \r\n",
    "        self.dropout = nn.Dropout(dropout)\r\n",
    "        \r\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\r\n",
    "        \r\n",
    "    def forward(self, query, key, value, mask = None):\r\n",
    "        \r\n",
    "        batch_size = query.shape[0]\r\n",
    "        \r\n",
    "        #query = [batch size, query len, hid dim]\r\n",
    "        #key = [batch size, key len, hid dim]\r\n",
    "        #value = [batch size, value len, hid dim]\r\n",
    "                \r\n",
    "        Q = self.fc_q(query)\r\n",
    "        K = self.fc_k(key)\r\n",
    "        V = self.fc_v(value)\r\n",
    "        \r\n",
    "        #Q = [batch size, query len, hid dim]\r\n",
    "        #K = [batch size, key len, hid dim]\r\n",
    "        #V = [batch size, value len, hid dim]\r\n",
    "                \r\n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
    "        \r\n",
    "        #Q = [batch size, n heads, query len, head dim]\r\n",
    "        #K = [batch size, n heads, key len, head dim]\r\n",
    "        #V = [batch size, n heads, value len, head dim]\r\n",
    "                \r\n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\r\n",
    "        \r\n",
    "        #energy = [batch size, n heads, query len, key len]\r\n",
    "        \r\n",
    "        if mask is not None:\r\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\r\n",
    "        \r\n",
    "        attention = torch.softmax(energy, dim = -1)\r\n",
    "                \r\n",
    "        #attention = [batch size, n heads, query len, key len]\r\n",
    "                \r\n",
    "        x = torch.matmul(self.dropout(attention), V)\r\n",
    "        \r\n",
    "        #x = [batch size, n heads, query len, head dim]\r\n",
    "        \r\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\r\n",
    "        \r\n",
    "        #x = [batch size, query len, n heads, head dim]\r\n",
    "        \r\n",
    "        x = x.view(batch_size, -1, self.hid_dim)\r\n",
    "        \r\n",
    "        #x = [batch size, query len, hid dim]\r\n",
    "        \r\n",
    "        x = self.fc_o(x)\r\n",
    "        \r\n",
    "        #x = [batch size, query len, hid dim]\r\n",
    "        \r\n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBFqGg5z-o_r"
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbTr7YPSMRpC"
   },
   "source": [
    "![](https://raw.githubusercontent.com/bentrevett/pytorch-seq2seq/9479fcb532214ad26fd4bda9fcf081a05e1aaf4e/assets/transformer-decoder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaHaOGNm_Isc"
   },
   "source": [
    "The architecture of a Decoder is very similar to that of the encoder with the significant differences resulting from the presence of input from two sources, the target sequence and the state representation vector from the encoder. Much like how we had an EncoderLayer block for Encoder, we will be having a DecoderLayer that accepts as input the combination of the embedding from the target token sequence(tok_embedding) and embedding of positional indices for these tokens. And as mentioned earlier, the encoder’s output also acts as one of the inputs to the DecoderLayer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWBMMF45MMNS"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\r\n",
    "    def __init__(self, \r\n",
    "                 output_dim, \r\n",
    "                 hid_dim, \r\n",
    "                 n_layers, \r\n",
    "                 n_heads, \r\n",
    "                 pf_dim, \r\n",
    "                 dropout, \r\n",
    "                 device,\r\n",
    "                 max_length = 10000):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "        self.device = device\r\n",
    "        \r\n",
    "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\r\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\r\n",
    "        \r\n",
    "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \r\n",
    "                                                  n_heads, \r\n",
    "                                                  pf_dim, \r\n",
    "                                                  dropout, \r\n",
    "                                                  device)\r\n",
    "                                     for _ in range(n_layers)])\r\n",
    "        \r\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\r\n",
    "        \r\n",
    "        self.dropout = nn.Dropout(dropout)\r\n",
    "        \r\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\r\n",
    "        \r\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\r\n",
    "        \r\n",
    "        #trg = [batch size, trg len]\r\n",
    "        #enc_src = [batch size, src len, hid dim]\r\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
    "        #src_mask = [batch size, 1, 1, src len]\r\n",
    "                \r\n",
    "        batch_size = trg.shape[0]\r\n",
    "        trg_len = trg.shape[1]\r\n",
    "        \r\n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\r\n",
    "                            \r\n",
    "        #pos = [batch size, trg len]\r\n",
    "\r\n",
    "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\r\n",
    "                \r\n",
    "        #trg = [batch size, trg len, hid dim]\r\n",
    "        \r\n",
    "        for layer in self.layers:\r\n",
    "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\r\n",
    "        \r\n",
    "        #trg = [batch size, trg len, hid dim]\r\n",
    "        #attention = [batch size, n heads, trg len, src len]\r\n",
    "        \r\n",
    "        output = self.fc_out(trg)\r\n",
    "        \r\n",
    "        #output = [batch size, trg len, output dim]\r\n",
    "            \r\n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcK1-4qZ_WBM"
   },
   "source": [
    "The DecoderLayer forms the building block of our Transformer’s decoder. Each DecoderLayer involves two attention operations:\r\n",
    "1. Self-attention on trg embedding.\r\n",
    "2. Multi-head attention operation that uses the trg as query vector and the encoder outputs act as the key and value vectors.\r\n",
    "\r\n",
    "The presence of an extra Multi-head attention operation differentiates the DecoderLayer from an EncoderLayer.\r\n",
    "\r\n",
    "The attention outputs from self-attention are normalized and combined with the trg embedding using a residual connection. This is then sent into the multi-head attention operation along with the encoder outputs. The attention layer outputs are then combined with the trg input again and normalized before sending it into the position-wise feedforward layer to generate the final outputs of the DecoderLayer.\r\n",
    "\r\n",
    "The purpose of all normalization operations is to prevent vanishing/exploding gradients during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMEr1IFUMxco"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\r\n",
    "    def __init__(self, \r\n",
    "                 hid_dim, \r\n",
    "                 n_heads, \r\n",
    "                 pf_dim, \r\n",
    "                 dropout, \r\n",
    "                 device):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
    "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\r\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
    "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \r\n",
    "                                                                     pf_dim, \r\n",
    "                                                                     dropout)\r\n",
    "        self.dropout = nn.Dropout(dropout)\r\n",
    "        \r\n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask):\r\n",
    "        \r\n",
    "        #trg = [batch size, trg len, hid dim]\r\n",
    "        #enc_src = [batch size, src len, hid dim]\r\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
    "        #src_mask = [batch size, 1, 1, src len]\r\n",
    "        \r\n",
    "        #self attention\r\n",
    "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\r\n",
    "        \r\n",
    "        #dropout, residual connection and layer norm\r\n",
    "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\r\n",
    "            \r\n",
    "        #trg = [batch size, trg len, hid dim]\r\n",
    "            \r\n",
    "        #encoder attention\r\n",
    "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\r\n",
    "        # query, key, value\r\n",
    "        \r\n",
    "        #dropout, residual connection and layer norm\r\n",
    "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\r\n",
    "                    \r\n",
    "        #trg = [batch size, trg len, hid dim]\r\n",
    "        \r\n",
    "        #positionwise feedforward\r\n",
    "        _trg = self.positionwise_feedforward(trg)\r\n",
    "        \r\n",
    "        #dropout, residual and layer norm\r\n",
    "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\r\n",
    "        \r\n",
    "        #trg = [batch size, trg len, hid dim]\r\n",
    "        #attention = [batch size, n heads, trg len, src len]\r\n",
    "        \r\n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udpPhQ2UN8oQ"
   },
   "source": [
    "The main class that implements a transformer for seq2seq problems is given below.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dr3Mg8OGN6ul"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\r\n",
    "    def __init__(self, \r\n",
    "                 encoder, \r\n",
    "                 decoder, \r\n",
    "                 src_pad_idx, \r\n",
    "                 trg_pad_idx, \r\n",
    "                 device):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "        self.encoder = encoder\r\n",
    "        self.decoder = decoder\r\n",
    "        self.src_pad_idx = src_pad_idx\r\n",
    "        self.trg_pad_idx = trg_pad_idx\r\n",
    "        self.device = device\r\n",
    "        \r\n",
    "    def make_src_mask(self, src):\r\n",
    "        \r\n",
    "        #src = [batch size, src len]\r\n",
    "        \r\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\r\n",
    "\r\n",
    "        #src_mask = [batch size, 1, 1, src len]\r\n",
    "\r\n",
    "        return src_mask\r\n",
    "    \r\n",
    "    def make_trg_mask(self, trg):\r\n",
    "        \r\n",
    "        #trg = [batch size, trg len]\r\n",
    "        \r\n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\r\n",
    "        \r\n",
    "        #trg_pad_mask = [batch size, 1, 1, trg len]\r\n",
    "        \r\n",
    "        trg_len = trg.shape[1]\r\n",
    "        \r\n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\r\n",
    "        \r\n",
    "        #trg_sub_mask = [trg len, trg len]\r\n",
    "            \r\n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\r\n",
    "        \r\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
    "        \r\n",
    "        return trg_mask\r\n",
    "\r\n",
    "    def forward(self, src, trg):\r\n",
    "        \r\n",
    "        #src = [batch size, src len]\r\n",
    "        #trg = [batch size, trg len]\r\n",
    "                \r\n",
    "        src_mask = self.make_src_mask(src)\r\n",
    "        trg_mask = self.make_trg_mask(trg)\r\n",
    "        \r\n",
    "        #src_mask = [batch size, 1, 1, src len]\r\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
    "        \r\n",
    "        enc_src = self.encoder(src, src_mask)\r\n",
    "        \r\n",
    "        #enc_src = [batch size, src len, hid dim]\r\n",
    "                \r\n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\r\n",
    "        \r\n",
    "        #output = [batch size, trg len, output dim]\r\n",
    "        #attention = [batch size, n heads, trg len, src len]\r\n",
    "        \r\n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvrK6zbF_2Fs"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4zsZjSSWOSHc"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(Input.vocab)\r\n",
    "OUTPUT_DIM = len(Output.vocab)\r\n",
    "HID_DIM = 256\r\n",
    "ENC_LAYERS = 3\r\n",
    "DEC_LAYERS = 3\r\n",
    "ENC_HEADS = 16\r\n",
    "DEC_HEADS = 16\r\n",
    "ENC_PF_DIM = 512\r\n",
    "DEC_PF_DIM = 512\r\n",
    "ENC_DROPOUT = 0.1\r\n",
    "DEC_DROPOUT = 0.1\r\n",
    "\r\n",
    "enc = Encoder(INPUT_DIM, \r\n",
    "              HID_DIM, \r\n",
    "              ENC_LAYERS, \r\n",
    "              ENC_HEADS, \r\n",
    "              ENC_PF_DIM, \r\n",
    "              ENC_DROPOUT, \r\n",
    "              device)\r\n",
    "\r\n",
    "dec = Decoder(OUTPUT_DIM, \r\n",
    "              HID_DIM, \r\n",
    "              DEC_LAYERS, \r\n",
    "              DEC_HEADS, \r\n",
    "              DEC_PF_DIM, \r\n",
    "              DEC_DROPOUT, \r\n",
    "              device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3vG-tI737e6",
    "outputId": "67f5f267-5b3e-40e3-80b8-da8b818c759a"
   },
   "outputs": [],
   "source": [
    "len(Output.vocab.__dict__['freqs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYVZYDVcOUGK"
   },
   "outputs": [],
   "source": [
    "SRC_PAD_IDX = Input.vocab.stoi[Input.pad_token]\r\n",
    "TRG_PAD_IDX = Output.vocab.stoi[Output.pad_token]\r\n",
    "\r\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qd0ePzj0OzLa",
    "outputId": "75e4ffdb-e5fb-4c9b-ba35-5c59d62868ff"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\r\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
    "\r\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmZ0hyo8O0vE"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(m):\r\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\r\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRtAM9Y4O2N2"
   },
   "outputs": [],
   "source": [
    "model.apply(initialize_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEpApG3YO3ZE"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\r\n",
    "\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95cvaGRg_-Ml"
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bs2XdrveCtDD"
   },
   "source": [
    "We have used augmentations in our dataset to mask variable literals. This means that our model can predict a variety of values for a particular variable and all of them are correct as long as the predictions are consistent through the code. This would mean that our training labels are not very certain and hence it would make more sense to treat them to be correct with probability ```1- smooth_eps``` and incorrect otherwise. This is what label smoothening enables us to do. The following is the implementation of CrossEntropyLoss with label smoothening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNfxmsLxD7yb"
   },
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import math\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "class CrossEntropyLoss(nn.CrossEntropyLoss):\r\n",
    "    \"\"\"CrossEntropyLoss - with ability to recieve distrbution as targets, and optional label smoothing\"\"\"\r\n",
    "\r\n",
    "    def __init__(self, weight=None, ignore_index=-100, reduction='mean', smooth_eps=None, smooth_dist=None, from_logits=True):\r\n",
    "        super(CrossEntropyLoss, self).__init__(weight=weight,\r\n",
    "                                               ignore_index=ignore_index, reduction=reduction)\r\n",
    "        self.smooth_eps = smooth_eps\r\n",
    "        self.smooth_dist = smooth_dist\r\n",
    "        self.from_logits = from_logits\r\n",
    "\r\n",
    "    def forward(self, input, target, smooth_dist=None):\r\n",
    "        if smooth_dist is None:\r\n",
    "            smooth_dist = self.smooth_dist\r\n",
    "        return cross_entropy(input, target, weight=self.weight, ignore_index=self.ignore_index,\r\n",
    "                             reduction=self.reduction, smooth_eps=self.smooth_eps,\r\n",
    "                             smooth_dist=smooth_dist, from_logits=self.from_logits)\r\n",
    "\r\n",
    "\r\n",
    "def cross_entropy(inputs, target, weight=None, ignore_index=-100, reduction='mean',\r\n",
    "                  smooth_eps=None, smooth_dist=None, from_logits=True):\r\n",
    "    \"\"\"cross entropy loss, with support for target distributions and label smoothing https://arxiv.org/abs/1512.00567\"\"\"\r\n",
    "    smooth_eps = smooth_eps or 0\r\n",
    "\r\n",
    "    # ordinary log-liklihood - use cross_entropy from nn\r\n",
    "    if _is_long(target) and smooth_eps == 0:\r\n",
    "        if from_logits:\r\n",
    "            return F.cross_entropy(inputs, target, weight, ignore_index=ignore_index, reduction=reduction)\r\n",
    "        else:\r\n",
    "            return F.nll_loss(inputs, target, weight, ignore_index=ignore_index, reduction=reduction)\r\n",
    "\r\n",
    "    if from_logits:\r\n",
    "        # log-softmax of inputs\r\n",
    "        lsm = F.log_softmax(inputs, dim=-1)\r\n",
    "    else:\r\n",
    "        lsm = inputs\r\n",
    "\r\n",
    "    masked_indices = None\r\n",
    "    num_classes = inputs.size(-1)\r\n",
    "\r\n",
    "    if _is_long(target) and ignore_index >= 0:\r\n",
    "        masked_indices = target.eq(ignore_index)\r\n",
    "\r\n",
    "    if smooth_eps > 0 and smooth_dist is not None:\r\n",
    "        if _is_long(target):\r\n",
    "            target = onehot(target, num_classes).type_as(inputs)\r\n",
    "        if smooth_dist.dim() < target.dim():\r\n",
    "            smooth_dist = smooth_dist.unsqueeze(0)\r\n",
    "        target.lerp_(smooth_dist, smooth_eps)\r\n",
    "\r\n",
    "    if weight is not None:\r\n",
    "        lsm = lsm * weight.unsqueeze(0)\r\n",
    "\r\n",
    "    if _is_long(target):\r\n",
    "        eps_sum = smooth_eps / num_classes\r\n",
    "        eps_nll = 1. - eps_sum - smooth_eps\r\n",
    "        likelihood = lsm.gather(dim=-1, index=target.unsqueeze(-1)).squeeze(-1)\r\n",
    "        loss = -(eps_nll * likelihood + eps_sum * lsm.sum(-1))\r\n",
    "    else:\r\n",
    "        loss = -(target * lsm).sum(-1)\r\n",
    "\r\n",
    "    if masked_indices is not None:\r\n",
    "        loss.masked_fill_(masked_indices, 0)\r\n",
    "\r\n",
    "    if reduction == 'sum':\r\n",
    "        loss = loss.sum()\r\n",
    "    elif reduction == 'mean':\r\n",
    "        if masked_indices is None:\r\n",
    "            loss = loss.mean()\r\n",
    "        else:\r\n",
    "            loss = loss.sum() / float(loss.size(0) - masked_indices.sum())\r\n",
    "\r\n",
    "    return loss\r\n",
    "\r\n",
    "\r\n",
    "def onehot(indexes, N=None, ignore_index=None):\r\n",
    "    \"\"\"\r\n",
    "    Creates a one-representation of indexes with N possible entries\r\n",
    "    if N is not specified, it will suit the maximum index appearing.\r\n",
    "    indexes is a long-tensor of indexes\r\n",
    "    ignore_index will be zero in onehot representation\r\n",
    "    \"\"\"\r\n",
    "    if N is None:\r\n",
    "        N = indexes.max() + 1\r\n",
    "    sz = list(indexes.size())\r\n",
    "    output = indexes.new().byte().resize_(*sz, N).zero_()\r\n",
    "    output.scatter_(-1, indexes.unsqueeze(-1), 1)\r\n",
    "    if ignore_index is not None and ignore_index >= 0:\r\n",
    "        output.masked_fill_(indexes.eq(ignore_index).unsqueeze(-1), 0)\r\n",
    "    return output\r\n",
    "\r\n",
    "def _is_long(x):\r\n",
    "    if hasattr(x, 'data'):\r\n",
    "        x = x.data\r\n",
    "    return isinstance(x, torch.LongTensor) or isinstance(x, torch.cuda.LongTensor)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RnWtafKlAhb_"
   },
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\r\n",
    "    # print(inp.shape, target.shape, mask.sum())\r\n",
    "    nTotal = mask.sum()\r\n",
    "    crossEntropy = CrossEntropyLoss(ignore_index = TRG_PAD_IDX, smooth_eps=0.20)\r\n",
    "    loss = crossEntropy(inp, target)\r\n",
    "    loss = loss.to(device)\r\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n9Dy_wWrO46l"
   },
   "outputs": [],
   "source": [
    "criterion = maskNLLLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQGdcEFmAxlO"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itmoGDi_tN74"
   },
   "source": [
    "In order to re-apply our augmentations differently in every epoch we re-create our dataset and dataloaders at the start of each epoch. This regularizes our training process and helps us come up with better models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycBBiEpuO6cG"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\r\n",
    "\r\n",
    "def make_trg_mask(trg):\r\n",
    "        \r\n",
    "        #trg = [batch size, trg len]\r\n",
    "        \r\n",
    "        trg_pad_mask = (trg != TRG_PAD_IDX).unsqueeze(1).unsqueeze(2)\r\n",
    "        \r\n",
    "        #trg_pad_mask = [batch size, 1, 1, trg len]\r\n",
    "        \r\n",
    "        trg_len = trg.shape[1]\r\n",
    "        \r\n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = device)).bool()\r\n",
    "        \r\n",
    "        #trg_sub_mask = [trg len, trg len]\r\n",
    "            \r\n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\r\n",
    "        \r\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
    "        \r\n",
    "        return trg_mask\r\n",
    "\r\n",
    "def train(model, iterator, optimizer, criterion, clip):\r\n",
    "    \r\n",
    "    model.train()\r\n",
    "    \r\n",
    "    n_totals = 0\r\n",
    "    print_losses = []\r\n",
    "    for i, batch in tqdm(enumerate(iterator), total=len(iterator)):\r\n",
    "        # print(batch)\r\n",
    "        loss = 0\r\n",
    "        src = batch.Input.permute(1, 0)\r\n",
    "        trg = batch.Output.permute(1, 0)\r\n",
    "        trg_mask = make_trg_mask(trg)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        \r\n",
    "        output, _ = model(src, trg[:,:-1])\r\n",
    "                \r\n",
    "        #output = [batch size, trg len - 1, output dim]\r\n",
    "        #trg = [batch size, trg len]\r\n",
    "            \r\n",
    "        output_dim = output.shape[-1]\r\n",
    "            \r\n",
    "        output = output.contiguous().view(-1, output_dim)\r\n",
    "        trg = trg[:,1:].contiguous().view(-1)\r\n",
    "                \r\n",
    "        #output = [batch size * trg len - 1, output dim]\r\n",
    "        #trg = [batch size * trg len - 1]\r\n",
    "            \r\n",
    "        mask_loss, nTotal = criterion(output, trg, trg_mask)\r\n",
    "        \r\n",
    "        mask_loss.backward()\r\n",
    "        \r\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
    "        \r\n",
    "        optimizer.step()\r\n",
    "        \r\n",
    "        print_losses.append(mask_loss.item() * nTotal)\r\n",
    "        n_totals += nTotal\r\n",
    "\r\n",
    "\r\n",
    "        \r\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zi3Ev8gaO79_"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\r\n",
    "    \r\n",
    "    model.eval()\r\n",
    "    \r\n",
    "    n_totals = 0\r\n",
    "    print_losses = []\r\n",
    "    \r\n",
    "    with torch.no_grad():\r\n",
    "    \r\n",
    "        for i, batch in tqdm(enumerate(iterator), total=len(iterator)):\r\n",
    "\r\n",
    "            src = batch.Input.permute(1, 0)\r\n",
    "            trg = batch.Output.permute(1, 0)\r\n",
    "            trg_mask = make_trg_mask(trg)\r\n",
    "\r\n",
    "            output, _ = model(src, trg[:,:-1])\r\n",
    "            \r\n",
    "            #output = [batch size, trg len - 1, output dim]\r\n",
    "            #trg = [batch size, trg len]\r\n",
    "            \r\n",
    "            output_dim = output.shape[-1]\r\n",
    "            \r\n",
    "            output = output.contiguous().view(-1, output_dim)\r\n",
    "            trg = trg[:,1:].contiguous().view(-1)\r\n",
    "            \r\n",
    "            #output = [batch size * trg len - 1, output dim]\r\n",
    "            #trg = [batch size * trg len - 1]\r\n",
    "            \r\n",
    "            mask_loss, nTotal = criterion(output, trg, trg_mask)\r\n",
    "\r\n",
    "            print_losses.append(mask_loss.item() * nTotal)\r\n",
    "            n_totals += nTotal\r\n",
    "\r\n",
    "        \r\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JuB4JqQRO9Wg"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\r\n",
    "    elapsed_time = end_time - start_time\r\n",
    "    elapsed_mins = int(elapsed_time / 60)\r\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aax76Ie4O_Cr",
    "outputId": "fbc1062f-f4d9-4ff4-887f-a365835c3de6"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 50\r\n",
    "CLIP = 1\r\n",
    "\r\n",
    "best_valid_loss = float('inf')\r\n",
    "\r\n",
    "for epoch in range(N_EPOCHS):\r\n",
    "    \r\n",
    "    start_time = time.time()\r\n",
    "    \r\n",
    "    train_example = []\r\n",
    "    val_example = []\r\n",
    "\r\n",
    "    for i in range(train_df.shape[0]):\r\n",
    "        try:\r\n",
    "            ex = data.Example.fromlist([train_df.question[i], train_df.solution[i]], fields)\r\n",
    "            train_example.append(ex)\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "\r\n",
    "    for i in range(val_df.shape[0]):\r\n",
    "        try:\r\n",
    "            ex = data.Example.fromlist([val_df.question[i], val_df.solution[i]], fields)\r\n",
    "            val_example.append(ex)\r\n",
    "        except:\r\n",
    "            pass       \r\n",
    "\r\n",
    "    train_data = data.Dataset(train_example, fields)\r\n",
    "    valid_data =  data.Dataset(val_example, fields)\r\n",
    "\r\n",
    "    BATCH_SIZE = 16\r\n",
    "    train_iterator, valid_iterator = BucketIterator.splits((train_data, valid_data), batch_size = BATCH_SIZE, \r\n",
    "                                                                sort_key = lambda x: len(x.Input),\r\n",
    "                                                                sort_within_batch=True, device = device)\r\n",
    "\r\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\r\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
    "    \r\n",
    "    end_time = time.time()\r\n",
    "    \r\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
    "    \r\n",
    "    if valid_loss < best_valid_loss:\r\n",
    "        best_valid_loss = valid_loss\r\n",
    "        torch.save(model.state_dict(), '/content/drive/MyDrive/TheSchoolOfAI/EndCapstone/model.pt')\r\n",
    "    \r\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMKkB13yPeJ7"
   },
   "outputs": [],
   "source": [
    "SRC = Input\r\n",
    "TRG = Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3_aq7QTPBFc",
    "outputId": "e8bdc0e6-cd7e-4d5e-bb92-1029c59ef9d6"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/content/drive/MyDrive/TheSchoolOfAI/EndCapstone/model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ieIjql9uPKH1"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50000):\r\n",
    "    \r\n",
    "    model.eval()\r\n",
    "        \r\n",
    "    if isinstance(sentence, str):\r\n",
    "        nlp = spacy.load('en')\r\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\r\n",
    "    else:\r\n",
    "        tokens = [token.lower() for token in sentence]\r\n",
    "\r\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\r\n",
    "        \r\n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\r\n",
    "\r\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\r\n",
    "    \r\n",
    "    src_mask = model.make_src_mask(src_tensor)\r\n",
    "    \r\n",
    "    with torch.no_grad():\r\n",
    "        enc_src = model.encoder(src_tensor, src_mask)\r\n",
    "\r\n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\r\n",
    "\r\n",
    "    for i in range(max_len):\r\n",
    "\r\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\r\n",
    "\r\n",
    "        trg_mask = model.make_trg_mask(trg_tensor)\r\n",
    "        \r\n",
    "        with torch.no_grad():\r\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\r\n",
    "        \r\n",
    "        pred_token = output.argmax(2)[:,-1].item()\r\n",
    "        \r\n",
    "        trg_indexes.append(pred_token)\r\n",
    "\r\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\r\n",
    "            break\r\n",
    "    \r\n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\r\n",
    "    \r\n",
    "    return trg_tokens[1:], attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mlHzigPJpLT"
   },
   "source": [
    "## Displaying Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WTBipndfPOlX"
   },
   "outputs": [],
   "source": [
    "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\r\n",
    "    \r\n",
    "    assert n_rows * n_cols == n_heads\r\n",
    "    \r\n",
    "    fig = plt.figure(figsize=(30,50))\r\n",
    "    \r\n",
    "    for i in range(n_heads):\r\n",
    "        \r\n",
    "        ax = fig.add_subplot(n_rows, n_cols, i+1)\r\n",
    "        \r\n",
    "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\r\n",
    "\r\n",
    "        cax = ax.matshow(_attention, cmap='bone')\r\n",
    "\r\n",
    "        ax.tick_params(labelsize=12)\r\n",
    "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \r\n",
    "                           rotation=45)\r\n",
    "        ax.set_yticklabels(['']+translation)\r\n",
    "\r\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
    "\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIyQeFx-dMlK",
    "outputId": "a8b2ce67-54a4-4298-f00b-4a6bcdfae999"
   },
   "outputs": [],
   "source": [
    "src = \"write a function that adds two numbers\"\r\n",
    "src=src.split(\" \")\r\n",
    "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
    "\r\n",
    "print(f'predicted trg sequence: ')\r\n",
    "print(translation)\r\n",
    "print(\"code: \\n\", untokenize(translation[:-1]).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CHWqhmvtPTJv",
    "outputId": "71e4428d-392a-4532-ae56-257747c55279"
   },
   "outputs": [],
   "source": [
    "display_attention(src, translation, attention)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhIC2mgfv37B"
   },
   "source": [
    "# Sample Outputs for English to Python translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lwaEkWxK8DA"
   },
   "source": [
    "Lets load our pretrained model to perform inference on a set of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_d2MUwHK62D",
    "outputId": "fec0c908-0a5a-4ea1-e318-e85762a5f927"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/content/drive/MyDrive/TheSchoolOfAI/EndCapstone/model_ep_0_pt_2.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vveLENmdLEE4"
   },
   "source": [
    "Function that translates an English src string to python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiYFFxnzj6Mn"
   },
   "outputs": [],
   "source": [
    "def eng_to_python(src):\r\n",
    "  src=src.split(\" \")\r\n",
    "  translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
    "\r\n",
    "  print(f'predicted trg: \\n')\r\n",
    "  # print(translation)\r\n",
    "  print(untokenize(translation[:-1]).decode('utf-8'))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TG3TsKgQWy4p"
   },
   "outputs": [],
   "source": [
    "SRC = Input\r\n",
    "TRG = Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBOoET5H6km5"
   },
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tuNEA7wzijhY",
    "outputId": "0eee0f83-b6d0-46c1-921c-f7b486ff1623"
   },
   "outputs": [],
   "source": [
    "src = \"program to sort a list of dictionaries by key\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FfPrg0l7ZNM"
   },
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lHOL5t7SjVeh",
    "outputId": "13322cb2-1500-4934-9727-c0df6232fefe"
   },
   "outputs": [],
   "source": [
    "src = \"function to merge two lists\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzJqBaYp7deR"
   },
   "source": [
    "## Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MuBCMCSjsR4",
    "outputId": "33c2dbac-3aff-48fb-e7a8-923bc0429273"
   },
   "outputs": [],
   "source": [
    "src = \"program to find gcd\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SnTjVI87vAp"
   },
   "source": [
    "## Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhq7YCN-kifr",
    "outputId": "50b27c35-7414-4c81-f751-e5309b5b870b"
   },
   "outputs": [],
   "source": [
    "src = \"program to calculate simple interest\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-USiTjDL7ydL"
   },
   "source": [
    "## Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8NO84A1ZlSJt",
    "outputId": "ae516f68-cce1-4db6-fae4-ef4f6e1c57a8"
   },
   "outputs": [],
   "source": [
    "src = \"function to sum odd elements of list\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fud3AeSZ71ft"
   },
   "source": [
    "## Example 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YOAWbmjfld7A",
    "outputId": "b51327e6-af22-441f-de4a-9bc56bc3a4fd"
   },
   "outputs": [],
   "source": [
    "src = \"program to multiply integers in a list\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aj3PvhIZ8GFN"
   },
   "source": [
    "## Example 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtwY2d_819Oi",
    "outputId": "0bfa3d0f-df3e-4e4d-d480-d33c37195356"
   },
   "outputs": [],
   "source": [
    "src = \"program to reverse a string\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tblyRJt58sO2"
   },
   "source": [
    "## Example 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GqEI8sqch-ms",
    "outputId": "0260f5f9-e072-4921-f4fd-b1a9b2da1646"
   },
   "outputs": [],
   "source": [
    "src = \"function to find reverse of a string\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bddDdZgk-AfF"
   },
   "source": [
    "## Example 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Krlfk6MxrHg8",
    "outputId": "0570785d-1054-4fad-fdd6-2e990d355018"
   },
   "outputs": [],
   "source": [
    "src = \"program to find the length of tuple\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSv3wBwQ-IWJ"
   },
   "source": [
    "## Example 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KcoA-tgmrHlz",
    "outputId": "dfed0cfd-61e7-4d1e-b6e7-902a4e879769"
   },
   "outputs": [],
   "source": [
    "src = \"program to find the area of a square\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkuQGH9T-NTn"
   },
   "source": [
    "## Example 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6ef4xQJrHrR",
    "outputId": "98678841-5c38-4061-94cd-dff426ace8f6"
   },
   "outputs": [],
   "source": [
    "src = \"program to print epoch timestamp\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6viTGKHA-Pte"
   },
   "source": [
    "## Example 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1K0vG_Uh-6T",
    "outputId": "2a43447b-c87a-4e94-84b1-7eb1ac57b562"
   },
   "outputs": [],
   "source": [
    "src = \"program to find ascii value of charecter\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1uI-bk0_xXj"
   },
   "source": [
    "## Example 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04a9ORHq52NO",
    "outputId": "369f7dfd-75cd-4895-e038-cb36d0a0892a"
   },
   "outputs": [],
   "source": [
    "src = \"function to find fibonacci sequence\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqst2jY0A8da"
   },
   "source": [
    "## Example 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOmQTvVe6BdW",
    "outputId": "eedccb72-7996-4e2e-cf89-bb8a2efdd6a5"
   },
   "outputs": [],
   "source": [
    "src = \"function to find largest element in a dictionary\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrzUWvbPA_yN"
   },
   "source": [
    "## Example 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GfikZjRnA6in",
    "outputId": "b1a07736-6a8c-40a9-bb32-18781ce0eefd"
   },
   "outputs": [],
   "source": [
    "src = \"program to convert list of tuples into a dictionary\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwGLVjeJBEse"
   },
   "source": [
    "## Example 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyjQlqrlBbd_",
    "outputId": "c607e278-935e-4a41-8e52-be636c29c591"
   },
   "outputs": [],
   "source": [
    "src = \"function to convert to binary\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCp9MFXuBz5f"
   },
   "source": [
    "## Example 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P92rLpfzB34-",
    "outputId": "3868f44b-39de-4ccc-a27b-ed88bdd973c7"
   },
   "outputs": [],
   "source": [
    "src = \"program to implement a linked list\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCzyMpcZB4M4"
   },
   "source": [
    "## Example 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JHvANCDoB7fu",
    "outputId": "fdb9bb36-0c31-401f-fde3-faeb2880e6b5"
   },
   "outputs": [],
   "source": [
    "src = \"program to add lists elementwise\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTWtnH5oEAnG"
   },
   "source": [
    "## Example 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "azuLJKtGEClE",
    "outputId": "b7bc923a-b9cf-435c-cb1f-189ad47892d0"
   },
   "outputs": [],
   "source": [
    "src = \"program to find common values between two sets\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bwss8KejEDIX"
   },
   "source": [
    "## Example 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4tnH_2qEDff",
    "outputId": "d1bbaeeb-8b91-4a6f-e8c5-79af7300903e"
   },
   "outputs": [],
   "source": [
    "src = \"program to find number of unique values in a list\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUrPbMgHEDtK"
   },
   "source": [
    "## Example 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYFV_FFYED81",
    "outputId": "6fca285c-6ed9-44a7-c6ad-140e82e916dc"
   },
   "outputs": [],
   "source": [
    "src = \"function to remove empty lists from a list of lists\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwD42Lm5Ek3p"
   },
   "source": [
    "## Example 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQHIADDYEnH6",
    "outputId": "1ba3d2ec-1245-4501-bcd9-1ea353219ce4"
   },
   "outputs": [],
   "source": [
    "src = \"write a function to capitalize a string\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffn0hW_yEnuq"
   },
   "source": [
    "## Example 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Vdu1QDbEq7a",
    "outputId": "82eb2d04-c24c-4658-dbef-d91f0366a03f"
   },
   "outputs": [],
   "source": [
    "src = \"write a function to find the area of a circle\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Xo7Je-HErTH"
   },
   "source": [
    "## Example 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qn4-1CW_EuRT",
    "outputId": "dbfcb747-f71c-4d51-8583-853d72321bc5"
   },
   "outputs": [],
   "source": [
    "src = \"write a python program to merge two dictionaries\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QbqAX4cEurC"
   },
   "source": [
    "## Example 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dxvGAM0Ewvp",
    "outputId": "e6c06519-55ed-4f38-a15b-7c9369c4c9bb"
   },
   "outputs": [],
   "source": [
    "src = \"write a function to find factorial\"\r\n",
    "\r\n",
    "eng_to_python(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MYIOx1D-KIZ9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "English to Python.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
